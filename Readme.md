# Proyecto: Pipeline de Detecci√≥n y Clasificaci√≥n de Im√°genes en el Navegador

Este proyecto es una aplicaci√≥n web que implementa un pipeline de visi√≥n por computadora de dos etapas directamente en el navegador del usuario. Utiliza la librer√≠a MediaPipe Tasks Vision de Google para realizar las siguientes acciones:

1.  **Detecci√≥n de Objetos:** Analiza una imagen proporcionada por el usuario para encontrar y localizar objetos gen√©ricos.
2.  **Clasificaci√≥n de Objetos:** Recorta cada objeto detectado y lo env√≠a a un segundo modelo, m√°s espec√≠fico, para obtener una clasificaci√≥n detallada.

Todo el procesamiento se realiza en el lado del cliente, lo que garantiza la privacidad del usuario y una respuesta r√°pida sin necesidad de un servidor.

## üöÄ C√≥mo Usar

El proyecto est√° contenido en un √∫nico archivo HTML. No requiere instalaci√≥n ni un servidor web.

1.  **Guarda el c√≥digo:** Aseg√∫rate de tener el archivo `index.html` (el c√≥digo que proporcionaste) en tu computadora.
2.  **√Åbrelo en un navegador:** Haz doble clic en el archivo `index.html` para abrirlo en un navegador web moderno (como Chrome, Firefox, Edge, etc.).
3.  **Selecciona una imagen:** Haz clic en el bot√≥n "Seleccionar archivo" y elige una imagen de tu computadora que contenga objetos.
4.  **Observa el resultado:** La aplicaci√≥n dibujar√° un cuadro sobre cada objeto detectado con una etiqueta que muestra tanto la detecci√≥n inicial como la clasificaci√≥n final.

## üõ†Ô∏è Tecnolog√≠as Utilizadas

-   **HTML5 / CSS3:** Para la estructura y el estilo de la p√°gina.
-   **JavaScript (ES Modules):** Para la l√≥gica de la aplicaci√≥n.
-   **MediaPipe Tasks Vision:** La librer√≠a de Google para ejecutar modelos de machine learning en el navegador.

### Modelos de Machine Learning

Este pipeline utiliza dos modelos pre-entrenados y alojados por MediaPipe:

1.  **Detector de Objetos:** `EfficientDet-Lite0 (float16)` - Un modelo r√°pido y eficiente para localizar objetos generales.
2.  **Clasificador de Im√°genes:** `EfficientNet-Lite0 (float32)` - Un modelo de alta precisi√≥n para clasificar im√°genes.

## üß† L√≥gica del Pipeline (Detectar ‚Üí Recortar ‚Üí Clasificar)

El n√∫cleo de esta aplicaci√≥n es su flujo de trabajo en dos etapas:

1.  **Detecci√≥n Global:** El modelo `ObjectDetector` recibe la imagen completa y devuelve las coordenadas (`bounding box`) de cada objeto que encuentra (ej: "dog", "chair").
2.  **Recorte Din√°mico:** Para cada `bounding box` encontrada, se crea un `<canvas>` temporal en memoria. Se utiliza para "recortar" esa secci√≥n espec√≠fica de la imagen original.
3.  **Clasificaci√≥n Espec√≠fica:** Cada imagen recortada (en su canvas temporal) se env√≠a al `ImageClassifier`. Este modelo, al estar enfocado en una sola cosa, puede dar un resultado mucho m√°s preciso (ej: "Golden Retriever", "Silla de oficina").
4.  **Visualizaci√≥n:** Finalmente, los resultados de ambos modelos se combinan y se dibujan sobre la imagen original para que el usuario pueda verlos.

## ‚ö†Ô∏è Nota Importante: Desaf√≠os con TFLite y la Transici√≥n a LiteRT

Durante el desarrollo de este proyecto, se explor√≥ la posibilidad de entrenar y utilizar un modelo personalizado en formato **TFLite**. Sin embargo, se encontraron importantes desaf√≠os t√©cnicos:

-   **Herramientas Obsoletas:** La librer√≠a `mediapipe-model-maker`, una herramienta clave para a√±adir los metadatos necesarios a los modelos TFLite para su uso con MediaPipe Tasks, presenta problemas de soporte y dependencias, lo que dificulta su uso en entornos locales.
-   **Falta de Soporte y Documentaci√≥n:** La documentaci√≥n y los ejemplos para el proceso de conversi√≥n de modelos Keras a un formato TFLite compatible con MediaPipe no est√°n actualizados, lo que lleva a un proceso de prueba y error muy complejo.
-   **Evoluci√≥n del Ecosistema:** Google est√° en proceso de transici√≥n de TensorFlow Lite a un nuevo runtime llamado **LiteRT**, optimizado para la inferencia en dispositivos de borde (edge). Esto significa que el soporte y las herramientas para el flujo de trabajo tradicional de TFLite est√°n siendo progresivamente depreciados.

Debido a estas dificultades, se tom√≥ la decisi√≥n de utilizar los modelos pre-entrenados y mantenidos por el equipo de MediaPipe para asegurar la funcionalidad y estabilidad del proyecto.

### Proceso de Entrenamiento (Modelo Personalizado)

A pesar de no poder integrarlo, se realiz√≥ el proceso de entrenamiento de un modelo personalizado con datos propios. El cuaderno de trabajo que documenta este proceso se puede encontrar en Google Colab:

-   **Cuaderno de Entrenamiento:** [Ver en Google Colab](https://colab.research.google.com/drive/1MFl2d2vjGq1cmlr-Putl_ZF_YGGjf9H9?usp=sharing)

### üìö Para saber m√°s sobre LiteRT

Para aquellos interesados en el futuro de la inferencia en el dispositivo, se recomienda consultar la documentaci√≥n oficial sobre LiteRT:

1.  **Anuncio Oficial:** [TensorFlow Lite is now LiteRT](https://developers.googleblog.com/en/tensorflow-lite-is-now-litert/)
2.  **Gu√≠a General:** [LiteRT Overview](https://ai.google.dev/edge/litert/guide)
3.  **Gu√≠a de Migraci√≥n:** [Migrate to LiteRT from TensorFlow Lite](https://ai.google.dev/edge/litert/migration)